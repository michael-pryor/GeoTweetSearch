[main_config]
# The server listens for connections on this IP/port
LISTEN_IP = 172.31.34.185
LISTEN_PORT = 80

MONGO_EXPLAINS_ENABLED = False

# The server makes external connections to twitter, and geocoding services.
# If we need to use a proxy we can.
# This feeds into requests API.
PROXIES_ENABLED = False

# This is for use with leaflet js, we get our map tiles from cloud made.
CLOUD_MADE_API_KEY = fillMeIn

# Used in 3 legged oauth, when twitter redirects user back to our website.
WEBSITE_ROOT = geotweetsearch.org

# For 3 legged oauth, identifies our twitter application.
CONSUMER_TOKEN = fillMeIn
CONSUMER_SECRET = fillMeIn

# MongoDB.
MONGO_DB_IP = localhost
MONGO_DB_PORT = 27017
MONGO_DB_DATABASE_NAME = fillMeIn
MONGO_DB_DATABASE_AUTHENTICATION_ENABLED = False
MONGO_DB_DATABASE_AUTHENTICATION_USER_NAME =
MONGO_DB_DATABASE_AUTHENTICATION_PASSWORD =

# When enriching follower information of a user, we make several attempts in case we fail.
MAX_FAILURES_ENRICH_USER_INFO = 4
MAX_FAILURES_GET_FOLLOWERS = 4

# If instance is not used it will be shut down and all data wiped.
# This is time in milliseconds.
# Usage = someone accessing a page.
# 1 hour.
#
# Must be less than server restart time, because this is not recovered on restart.
MAX_INSTANCE_INACTIVE_TIME_MS = 3600000

# 1 day.
MAX_INSTANCE_TOTAL_AGE_MS = 86400000

# Global flag, if false influence sources will not automatically enrich
# follower information.
AUTO_ENRICH_FOLLOWER_INFO_ENABLED = True

# Maximum number of tweets per location per instance that
# are live. This means they are stored in memory and sent
# to users when they first open the location page.
#
# The users page will then continue to display additional tweets
# up until MAX_CLIENT_LIVE_TWEETS.
#
# On the server and client side tweets are discarded in FIFO order.
MAX_SERVER_LIVE_TWEETS = 20
MAX_CLIENT_LIVE_TWEETS = 200

# Twitter place data is ignored unless it is a type in this list.
REQUIRED_TWITTER_PLACE_TYPES = city

# Route on file system to static files.
WEB_STATIC_ROUTE = /static

# GE_GOOGLE and GE_MAP_QUEST are external data providers.
# GE_GEO_NET represents internal memory that we load from a CSV file
# containing country and continent information.
# To switch between external providers you only need to change
# GEOCODE_EXTERNAL_PROVIDER. Everything will run as normal without
# further configuration changes.
#
# Possible options:
# - GE_GOOGLE = 1
# - GE_MAP_QUEST = 2
# - GE_GEO_NET = 3 <- included for completion sake, should not set GEOCODE_EXTERNAL_PROVIDER to this.
GEOCODE_EXTERNAL_PROVIDER = 1

# When users download CSV files, if we dont have information for a field
# we will place this string in its place as a default value.
CSV_EMPTY_VAL = -

# For temporal data we collect it in groups known as temporal steps.
# The step represents the unit of time we can differentiate between.
# So if the step is 1 hour, we can only view hour segments, and wont
# be able to look at individual minutes within each hour.
# However, the smaller the temporal step the more storage required.
# This value is specified in milliseconds.
TEMPORAL_STEP = 15000

# We store geocode data in memory aswell as in the database for performance.
# This value is the number of geocode entries to store in memory at any one time.
# The in memory cache is a least recently used cache.
GEOCODE_IN_MEMORY_CACHE_SIZE = 1000

# Files to load GE_GEO_NET data from.
COUNTRY_DATA_CSV = /home/ec2-user/GeoTweetSearch/country_data.csv
CONTINENT_DATA_CSV = /home/ec2-user/GeoTweetSearch/continent_data.csv

# Twitter specifies maximum 25 geographical areas may
# be specified in connection to streaming API.
# This value sets an input limit on the instance setup page.
TWITTER_MAX_GEO_FILTERS = 25

# Specifies whether bottle should operate in debug mode.
BOTTLE_DEBUG = False


# Not sure what this is, don't think we ever want to wait?
GEOCODE_FROM_CACHE_THREAD_WAIT_TIME_MS = 0

# Geocode from an in memory cache.
NUM_GEOCODE_FROM_CACHE_WORKERS_MEMORY_ONLY = 1

# Geocode from the database.
# Set high because its IO bound.
NUM_GEOCODE_FROM_CACHE_WORKERS = 2

NUM_ANALYSIS_WORKERS = 3

# I think this applies to both in memory and database failover queue size.
GEOCODE_FROM_CACHE_PRIMARY_FAILURE_OUTPUT_QUEUE_SIZE = 100

ANALYSIS_INPUT_THREAD_SIZE_CAP = 100
